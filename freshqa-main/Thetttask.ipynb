{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_18036\\1185410051.py:140: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  n_days = int(re.search(\"(\\d+) days? ago\", d).group(1))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "import dateutil\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from openai import OpenAI\n",
    "import tabulate\n",
    "import textwrap\n",
    "\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "current_date = datetime.datetime.now(\n",
    "        pytz.timezone(\"America/Los_Angeles\")\n",
    "    ).strftime(\"%B %d, %Y\")\n",
    "#@title API keys\n",
    "\n",
    "\n",
    "# OpenAI's API key (sign up at https://platform.openai.com/signup to get $5 in\n",
    "# free credit that can be used during your first 3 months)\n",
    "\n",
    "# 设置API-KEY\n",
    "openai_api_key = \"sk-JnWHmZFfrx9mWDahm7pJhfDoQNON5zDtm4jabuapWyp09yll\"  # @param {type:\"string\"}\n",
    "openai_client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
    ")\n",
    "\n",
    "# SerpApi's API key (sign up at https://serpapi.com/users/sign_up?plan=free for\n",
    "# a free plan with 100 searches/month)\n",
    "serpapi_api_key = \"608a172cd041ef113d8365d60d2129dfb80218fea80eb0c361f46ab4d91465b5\"  # @param {type:\"string\"}\n",
    "\n",
    "assert (\n",
    "    openai_api_key is not None and openai_api_key != \"\"\n",
    "), \"OpenAI's API key is not set\"\n",
    "assert (\n",
    "    serpapi_api_key is not None and serpapi_api_key != \"\"\n",
    "), \"SerpApi's API key is not set\"\n",
    "\n",
    "# @title Function calling for the search engine\n",
    "\n",
    "# 调用搜索引擎\n",
    "def call_search_engine(query):\n",
    "  params = {\n",
    "    \"q\": query,\n",
    "    # \"location\": \"California, United States\",\n",
    "    \"hl\": \"en\",\n",
    "    \"gl\": \"us\",\n",
    "    \"google_domain\": \"google.com\",\n",
    "    \"api_key\": serpapi_api_key,\n",
    "\n",
    "  }\n",
    "\n",
    "  search = GoogleSearch(params)\n",
    "  return search.get_dict()\n",
    "\n",
    "# 调用LLM的API函数\n",
    "def call_llm_api(prompt, model, temperature, max_tokens, chat_completions=True):\n",
    "    \"\"\"\n",
    "    调用LLM（大型语言模型）的API以生成响应文本。\n",
    "\n",
    "    参数：\n",
    "    - prompt: 用户输入的提示文本\n",
    "    - model: 要使用的语言模型\n",
    "    - temperature: 设置生成文本的随机性（温度参数）\n",
    "    - max_tokens: 设置生成文本的最大长度\n",
    "    - chat_completions: 指定是否使用聊天模式，默认为True\n",
    "\n",
    "    返回：\n",
    "    - 生成的响应文本\n",
    "    \"\"\"\n",
    "\n",
    "    # 参见OpenAI文档获取详细信息：https://platform.openai.com/docs/guides/gpt\n",
    "    if chat_completions:\n",
    "        # 调用聊天模式的API\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,  # 使用指定的模型\n",
    "            temperature=temperature,  # 设置生成文本的随机性\n",
    "            max_tokens=max_tokens,  # 设置生成文本的最大长度\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",  # 系统角色消息，用于设置助手的行为\n",
    "                    \"content\": (\n",
    "                        \"You are a helpful assistant. Answer as concisely as\"\n",
    "                        f\" possible. Knowledge cutoff: {current_date}.\"  # 提供上下文和知识截断日期\n",
    "                    ),\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": \"What's today's date?\"},  # 用户消息示例\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"Today is {current_date} in Pacific Standard Time.\",  # 助手响应示例\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},  # 实际用户提示消息\n",
    "            ],\n",
    "        )\n",
    "        return response.choices[0].message.content  # 返回生成的文本内容\n",
    "\n",
    "    else:\n",
    "        # 调用完成模式的API\n",
    "        response = openai_client.completions.create(\n",
    "            model=model,  # 使用指定的模型\n",
    "            temperature=temperature,  # 设置生成文本的随机性\n",
    "            max_tokens=max_tokens,  # 设置生成文本的最大长度\n",
    "            prompt=prompt,  # 实际用户提示\n",
    "        )\n",
    "        return response.choices[0].text  # 返回生成的文本内容\n",
    "\n",
    "\n",
    "# 判断是否为日期\n",
    "def is_date(string, fuzzy=False):\n",
    "    # Parse a string into a date and check its validity\n",
    "    try:\n",
    "        dateutil.parser.parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def format_date(d):\n",
    "    # Standardize the date format for each search result\n",
    "    date = dateutil.parser.parse(current_date, fuzzy=True).strftime(\"%b %d, %Y\")\n",
    "    if d is None:\n",
    "        return None\n",
    "\n",
    "    for t in [\"second\", \"minute\", \"hour\"]:\n",
    "        if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
    "            return date\n",
    "\n",
    "    t = \"day\"\n",
    "    if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
    "        n_days = int(re.search(\"(\\d+) days? ago\", d).group(1))\n",
    "        return (\n",
    "            datetime.datetime.strptime(date, \"%b %d, %Y\")\n",
    "            - datetime.timedelta(days=n_days)\n",
    "        ).strftime(\"%b %d, %Y\")\n",
    "\n",
    "    try:\n",
    "        return dateutil.parser.parse(d, fuzzy=True).strftime(\"%b %d, %Y\")\n",
    "    except ValueError:\n",
    "        for x in d.split():\n",
    "            if is_date(x):\n",
    "                return dateutil.parser.parse(x, fuzzy=True).strftime(\"%b %d, %Y\")\n",
    "\n",
    "def extract_source_webpage(link):\n",
    "    # Extract source webpage\n",
    "    return (\n",
    "        link.strip()\n",
    "        .replace(\"https://www.\", \"\")\n",
    "        .replace(\"http://www.\", \"\")\n",
    "        .replace(\"https://\", \"\")\n",
    "        .replace(\"http://\", \"\")\n",
    "        .split(\"/\")[0]\n",
    "    )\n",
    "\n",
    "def simplify_displayed_link(displayed_link):\n",
    "    # Simplify displayed link\n",
    "    if displayed_link is None:\n",
    "        return None\n",
    "    return extract_source_webpage(displayed_link.split(' › ')[0])\n",
    "\n",
    "# 格式化搜索结果\n",
    "def format_search_results(search_data, title_field=None, highlight_field=None):\n",
    "    # Standardize search results as shown in Figure 3 (left) in the paper\n",
    "    '''\n",
    "    参数：\n",
    "    - search_data: 包含搜索结果数据的字典\n",
    "    - title_field: 可选，指定用于标题的字段\n",
    "    - highlight_field: 可选，指定用于高亮显示的字段\n",
    "\n",
    "    返回：\n",
    "    - 一个包含格式化后的搜索结果的字典\n",
    "    '''\n",
    "    # 标准化字段\"snippet_highlighted_words\"\n",
    "    field = 'snippet_highlighted_words'\n",
    "    if field in search_data and isinstance(search_data[field], list):\n",
    "        search_data[field] = ' | '.join(search_data[field])\n",
    "    # 标准化字段\"displayed_link\"\n",
    "    field = 'displayed_link'\n",
    "    if field in search_data:\n",
    "        search_data[field] = simplify_displayed_link(search_data[field])\n",
    "\n",
    "    # edge case 1：处理特定类型\"local_time\"的边缘情况\n",
    "    if search_data.get('type') == 'local_time':\n",
    "        source = search_data.get('displayed_link')\n",
    "        date = format_date(search_data.get('date'))\n",
    "        title = search_data.get('title')\n",
    "\n",
    "        snippet = search_data.get('snippet')\n",
    "        if snippet is None and 'result' in search_data:\n",
    "            if 'extensions' in search_data and isinstance(\n",
    "                search_data['extensions'], list\n",
    "            ):\n",
    "                snippet = '\\n\\t'.join(\n",
    "                    [search_data['result']] + search_data['extensions']\n",
    "                )\n",
    "            else:\n",
    "                snippet = search_data['result']\n",
    "\n",
    "        highlight = search_data.get('snippet_highlighted_words')\n",
    "        if highlight is None and 'result' in search_data:\n",
    "            highlight = search_data['result']\n",
    "\n",
    "    # edge case 2：处理特定类型\"population_result\"的边缘情况\n",
    "    elif 'type' in search_data and search_data['type'] == 'population_result':\n",
    "        source = search_data.get('displayed_link')\n",
    "        if source is None and 'sources' in search_data:\n",
    "            if (\n",
    "                isinstance(search_data['sources'], list)\n",
    "                and 'link' in search_data['sources'][0]\n",
    "            ):\n",
    "                source = extract_source_webpage(search_data['sources'][0]['link'])\n",
    "\n",
    "        date = format_date(search_data.get('date'))\n",
    "        if date is None and 'year' in search_data:\n",
    "            date = format_date(search_data['year'])\n",
    "\n",
    "        title = search_data.get('title')\n",
    "\n",
    "        snippet = search_data.get('snippet')\n",
    "        if snippet is None and 'population' in search_data:\n",
    "            if 'place' in search_data:\n",
    "                snippet = '\\n\\t'.join(\n",
    "                    [\n",
    "                        f\"{search_data['place']} / Population\",\n",
    "                    ]\n",
    "                    + [\n",
    "                        search_data['population'],\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                snippet = search_data['population']\n",
    "\n",
    "        highlight = search_data.get('snippet_highlighted_words')\n",
    "        if highlight is None and 'population' in search_data:\n",
    "            highlight = search_data['population']\n",
    "\n",
    "    # 处理其他类型的情况\n",
    "    else:\n",
    "        source = search_data.get('displayed_link')\n",
    "        date = format_date(search_data.get('date'))\n",
    "        title = (\n",
    "            search_data.get('title')\n",
    "            if title_field is None\n",
    "            else search_data.get(title_field)\n",
    "        )\n",
    "        highlight = (\n",
    "            search_data.get('snippet_highlighted_words')\n",
    "            if highlight_field is None\n",
    "            else search_data.get(highlight_field)\n",
    "        )\n",
    "        snippet = search_data.get('snippet', '')\n",
    "        # 处理'rich_snippet'字段\n",
    "        if 'rich_snippet' in search_data:\n",
    "            for key in ['top', 'bottom']:\n",
    "                if (\n",
    "                    key in search_data['rich_snippet']\n",
    "                    and 'extensions' in search_data['rich_snippet'][key]\n",
    "                ):\n",
    "                    snippet = '\\n\\t'.join(\n",
    "                        [snippet] + search_data['rich_snippet'][key]['extensions']\n",
    "                    )\n",
    "        # 处理\"list\"字段\n",
    "        if 'list' in search_data:\n",
    "            assert isinstance(search_data['list'], list)\n",
    "            snippet = '\\n\\t'.join([snippet] + search_data['list'])\n",
    "        # 处理\"contents\"字段中的table\n",
    "        if 'contents' in search_data and 'table' in search_data['contents']:\n",
    "            tbl = search_data['contents']['table']\n",
    "            assert isinstance(tbl, list)\n",
    "            snippet += '\\n'\n",
    "            for row in tbl:\n",
    "                snippet += f'\\n{\",\".join(row)}'\n",
    "        # 如果snippet是空白字符串，将其设置为None\n",
    "        if snippet is not None and snippet.strip() == '':\n",
    "            snippet = None\n",
    "    # 返回成固定的格式\n",
    "    return {\n",
    "        'source': source,\n",
    "        'date': date,\n",
    "        'title': title,\n",
    "        'snippet': snippet,\n",
    "        'highlight': highlight,\n",
    "    }\n",
    "\n",
    "# 格式化知识图谱\n",
    "def format_knowledge_graph(search_data):\n",
    "    # Standardize knowledge graphs as shown in Figure 3 (left) in the paper\n",
    "    source = None\n",
    "    if \"source\" in search_data and \"link\" in search_data[\"source\"]:\n",
    "        source = extract_source_webpage(search_data[\"source\"][\"link\"])\n",
    "\n",
    "    date = None\n",
    "\n",
    "    title = None\n",
    "    if \"title\" in search_data:\n",
    "        title = search_data[\"title\"]\n",
    "        if \"type\" in search_data:\n",
    "            title += f\"\\n\\t{search_data['type']}\"\n",
    "\n",
    "    snippet = \"\"\n",
    "    for field in search_data:\n",
    "        if (\n",
    "            (field not in [\"title\", \"type\", \"kgmid\"])\n",
    "            and (\"_link\" not in field)\n",
    "            and (\"_stick\" not in field)\n",
    "            and isinstance(search_data[field], str)\n",
    "            and not search_data[field].startswith(\"http\")\n",
    "        ):\n",
    "            snippet += f\"\\n\\t{field}: {search_data[field]}\"\n",
    "\n",
    "    if snippet.strip() == \"\":\n",
    "        snippet = None\n",
    "    else:\n",
    "        snippet = snippet.strip()\n",
    "\n",
    "    highlight = None\n",
    "\n",
    "    return {\n",
    "        \"source\": source,\n",
    "        \"date\": date,\n",
    "        \"title\": title,\n",
    "        \"snippet\": snippet,\n",
    "        \"highlight\": highlight,\n",
    "    }\n",
    "\n",
    "\n",
    "# 格式化 Q and A\n",
    "def format_questions_and_answers(search_data):\n",
    "    # Standardize questions and answers as shown in Figure 3 (left) in the paper\n",
    "    source = None\n",
    "    if \"link\" in search_data:\n",
    "        source = extract_source_webpage(search_data[\"link\"])\n",
    "\n",
    "    date = None\n",
    "\n",
    "    title = None\n",
    "    if \"question\" in search_data:\n",
    "        title = search_data[\"question\"]\n",
    "\n",
    "    snippet = None\n",
    "    if \"answer\" in search_data:\n",
    "        snippet = search_data[\"answer\"]\n",
    "\n",
    "    highlight = None\n",
    "\n",
    "    return {\n",
    "        \"source\": source,\n",
    "        \"date\": date,\n",
    "        \"title\": title,\n",
    "        \"snippet\": snippet,\n",
    "        \"highlight\": highlight,\n",
    "    }\n",
    "\n",
    "# 对freshprompt进行格式化\n",
    "def freshprompt_format(\n",
    "    question,\n",
    "    search_data,\n",
    "    reasoning_and_answer,\n",
    "    num_organic_results,\n",
    "    num_related_questions,\n",
    "    num_questions_and_answers,\n",
    "    num_retrieved_evidences,\n",
    "):\n",
    "    \"\"\"Build FreshPrompt for each question\n",
    "\n",
    "    Args:\n",
    "        question: The question to process.\n",
    "        search_data: Search data.\n",
    "        reasoning_and_answer: The reasoning and answer.\n",
    "        num_organic_results: Number of organic results to keep.\n",
    "        num_related_questions: Number of related questions to keep.\n",
    "        num_questions_and_answers: Number of questions and answers to keep.\n",
    "        num_retrieved_evidences: Number of retrieved evidences to keep.\n",
    "\n",
    "    Returns:\n",
    "        A prompt that incorporates retrieved evidences for each question.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(columns=['source', 'date', 'title', 'snippet', 'highlight'])\n",
    "\n",
    "    # Organic results\n",
    "    organic_results = [None] * num_organic_results\n",
    "    for k in range(num_organic_results):\n",
    "        if (\n",
    "            'organic_results' in search_data\n",
    "            and len(search_data['organic_results']) > k\n",
    "        ):\n",
    "            organic_results[k] = format_search_results(\n",
    "                search_data['organic_results'][k]\n",
    "            )\n",
    "        else:\n",
    "            organic_results[k] = format_search_results({})\n",
    "\n",
    "    for d in organic_results[::-1]:\n",
    "        df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
    "\n",
    "    # Related questions\n",
    "    related_questions = [None] * num_related_questions\n",
    "    for k in range(num_related_questions):\n",
    "        if (\n",
    "            'related_questions' in search_data\n",
    "            and len(search_data['related_questions']) > k\n",
    "        ):\n",
    "            related_questions[k] = format_search_results(\n",
    "                search_data['related_questions'][k], title_field='question'\n",
    "            )\n",
    "        else:\n",
    "            related_questions[k] = format_search_results({})\n",
    "\n",
    "    for d in related_questions[::-1]:\n",
    "        df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
    "\n",
    "    # Questions and Answers\n",
    "    questions_and_answers = [None] * num_questions_and_answers\n",
    "    for k in range(num_questions_and_answers):\n",
    "        if (\n",
    "            'questions_and_answers' in search_data\n",
    "            and len(search_data['questions_and_answers']) > k\n",
    "        ):\n",
    "            questions_and_answers[k] = format_questions_and_answers(\n",
    "                search_data['questions_and_answers'][k]\n",
    "            )\n",
    "        else:\n",
    "            questions_and_answers[k] = format_questions_and_answers({})\n",
    "\n",
    "    for d in questions_and_answers[::-1]:\n",
    "        df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
    "\n",
    "    # Knowledge graph\n",
    "    knowledge_graph = None\n",
    "    if 'knowledge_graph' in search_data:\n",
    "        knowledge_graph = format_knowledge_graph(search_data['knowledge_graph'])\n",
    "    else:\n",
    "        knowledge_graph = format_knowledge_graph({})\n",
    "    df = pd.concat([df, pd.DataFrame([knowledge_graph])], ignore_index=True)\n",
    "\n",
    "    # Answer box\n",
    "    answer_box = None\n",
    "    if 'answer_box' in search_data:\n",
    "        answer_box = format_search_results(\n",
    "            search_data['answer_box'], highlight_field='answer'\n",
    "        )\n",
    "    else:\n",
    "        answer_box = format_search_results({})\n",
    "    df = pd.concat([df, pd.DataFrame([answer_box])], ignore_index=True)\n",
    "\n",
    "    # Sort by date\n",
    "    df['date'] = df['date'].apply(lambda x: format_date(x))\n",
    "    df['datetime'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df = df.sort_values(by='datetime', na_position='first')\n",
    "    df.replace({pd.NaT: None}, inplace=True)\n",
    "    df = df.dropna(how='all')\n",
    "\n",
    "    # Select top_k supporting evidences overall\n",
    "    evidences = []\n",
    "\n",
    "    for _, row in df.tail(num_retrieved_evidences).iterrows():\n",
    "        evidences.append(\n",
    "            f\"\"\"\\n\\nsource: {row['source']}\\ndate: {row['date']}\\ntitle: {row['title']}\\nsnippet: {row['snippet']}\\nhighlight: {row['highlight']}\"\"\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        ''.join(\n",
    "            [\n",
    "                f'\\n\\n\\nquery: {question}',\n",
    "            ]\n",
    "            + evidences\n",
    "        )\n",
    "        + f'\\n\\nquestion: {question}{reasoning_and_answer}'\n",
    "    )\n",
    "\n",
    "# 后面的针对用户提的问题的prompt就直接拼接在这个demo_prompts后就好\n",
    "freshprompt_demo = \"\"\"\n",
    "query: What year is considered Albert Einstein's annus mirabilis?\n",
    "\n",
    "source: quora.com\n",
    "date: None\n",
    "title: What caused Einstein's annus mirabilis?\n",
    "snippet: No. He was smarter. He was so smart that “they” are probably fundamentally incapable of understanding just how “smart” Einstein was. Around 1900, Lord Kelvin, a physicist so brilliant they named a unit after him, famously recommended that young students not study physics, because so little remained to be done. He listed, specifically, two remaining issues to be solved, after which all that remained was to do ever better measurements: the photoelectric effect and the absence of a result in the Michelson-Morley experiment. He might well have added the Ultraviolet Catastrophe. Einstein was the person who solved both those riddles (and the Ultraviolet Catastrophe in the bargain), and the answers were what 20th century physics was all about: relativity and quantum mechanics. These two are arguably the most profound breakthroughs in our understanding of the world around us in all of human history. He basically single-handedly created modern physics. And in addition to that, there is basic…\n",
    "highlight: None\n",
    "\n",
    "source: bbvaopenmind.com\n",
    "date: Jun 30, 2015\n",
    "title: Einstein's Miracle Year - BBVA OpenMind\n",
    "snippet: Einstein's miraculous year: 1905. He published four key studies for our current conception of different aspects of reality: light, matter, ...\n",
    "highlight: 1905\n",
    "\n",
    "source: guides.loc.gov\n",
    "date: Nov 06, 2019\n",
    "title: Introduction - Annus Mirabilis of Albert Einstein\n",
    "snippet: In 1905 Albert Einstein published four groundbreaking papers that revolutionized scientific understanding of the universe.\n",
    "highlight: 1905\n",
    "\n",
    "source: cantorsparadise.com\n",
    "date: Jul 18, 2023\n",
    "title: Einstein's Miraculous Year: A Summary of the 1905 Annus ...\n",
    "snippet: These are the four papers that Albert Einstein published in 1905, which are considered to be the foundation of modern physics.\n",
    "highlight: 1905\n",
    "\n",
    "source: guides.loc.gov\n",
    "date: Jan 26, 2024\n",
    "title: The 1905 Papers - Annus Mirabilis of Albert Einstein\n",
    "snippet: It is an English translation of all his writings, while the second book is where the four 1905 papers were published in the original German. For ...\n",
    "highlight: 1905\n",
    "\n",
    "question: What year is considered Albert Einstein's annus mirabilis?\n",
    "answer: As of today May 27, 2024, the most up-to-date and relevant information regarding this query is as follows. 1905 is considered Albert Einstein's annus mirabilis, his miraculous year.\n",
    "\n",
    "\n",
    "query: Which photographer took the most expensive photograph in the world?\n",
    "\n",
    "source: en.wikipedia.org\n",
    "date: None\n",
    "title: List\n",
    "snippet: \n",
    "Rank,Artist,Date\n",
    "1,Man Ray,May 14, 2022\n",
    "2,Edward Steichen,Nov 10, 2022\n",
    "3,Andreas Gursky,November 8, 2011\n",
    "4,Richard Prince,May 12, 2014\n",
    "highlight: None\n",
    "\n",
    "source: all-about-photo.com\n",
    "date: Dec 22, 2019\n",
    "title: Most expensive photographs ever sold | Photo Article\n",
    "snippet: The most expensive photo in history as of December 2014 is $6.5 million! The work of Australian landscape photographer Peter Lik, Phantom is a ...\n",
    "highlight: Australian landscape photographer Peter Lik, Phantom\n",
    "\n",
    "source: all-about-photo.com\n",
    "date: Dec 20, 2022\n",
    "title: Was the most expensive photograph ever taken was sold for $22 million?\n",
    "snippet: The most expensive image ever sold at auction, Le Violon d'Ingres (1924) by Man Ray, which features a nude woman's back superimposed with a violin's f-holes, sold for $12.4 million on May 14th, 2022 at Christie's New York.\n",
    "highlight: None\n",
    "\n",
    "source: barnebys.com\n",
    "date: May 15, 2023\n",
    "title: The 11 Most Expensive Photographers\n",
    "snippet: From Vogue icon Helmut Newton to feminist art pioneer Cindy Sherman, these photographers have produced indelible images that command equally ...\n",
    "highlight: Vogue icon Helmut Newton\n",
    "\n",
    "source: artisanhd.com\n",
    "date: Dec 19, 2023\n",
    "title: Top 5 Most Expensive Photographs & Why We Love Them\n",
    "snippet: Our Top 5 Favorite Most Expensive Photographs · Andreas Gursky: Rhein II (1999) – $4.3M · Edward Steichen: The Flatiron – $11.8M · Richard Prince: ...\n",
    "\t4.7store rating (134)\n",
    "\t‎Free 3–9 day delivery\n",
    "\t‎10\n",
    "\tday returns\n",
    "highlight: Andreas Gursky: Rhein II\n",
    "\n",
    "question: Which photographer took the most expensive photograph in the world?\n",
    "answer: As of today May 27, 2024, the most up-to-date and relevant information regarding this query is as follows. The most expensive photograph in the world is \"Le Violon d'Ingres\". The photograph was created by Man Ray.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 调用 freshprompt 函数\n",
    "\n",
    "def call_freshprompt(model, question, check_premise=False, verbose=False):\n",
    "    # 初始化模型参数\n",
    "    temperature = 0.0  # 模型的温度参数，影响生成结果的随机性\n",
    "    max_tokens = 256  # 最大生成的token数量\n",
    "    chat_completions = True  # 是否使用对话完成模式\n",
    "\n",
    "    # 根据模型类型设置不同的参数\n",
    "    if model.startswith('gpt-4'):\n",
    "        num_organic_results = 15  # 自然搜索结果数量\n",
    "        num_related_questions = 3  # 相关问题数量\n",
    "        num_questions_and_answers = 3  # 问答对数量\n",
    "        num_retrieved_evidences = 15  # 检索到的证据数量\n",
    "    else:\n",
    "        num_organic_results = 15\n",
    "        num_related_questions = 2\n",
    "        num_questions_and_answers = 2\n",
    "        num_retrieved_evidences = 5\n",
    "    \n",
    "    # 根据是否检查前提来设置后缀\n",
    "    if check_premise:\n",
    "        suffix = (\n",
    "            \"\\nPlease check if the question contains a valid premise before\"\n",
    "            \" answering.\\nanswer: \"\n",
    "        )\n",
    "    else:\n",
    "        suffix = \"\\nanswer: \"\n",
    "\n",
    "    # 生成用户问题的提示\n",
    "    freshprompt_question = freshprompt_format(\n",
    "        question,  # 用户问题\n",
    "        call_search_engine(question),  # 调用搜索引擎获取相关数据\n",
    "        suffix,  # 后缀\n",
    "        num_organic_results,  # 结果\n",
    "        num_related_questions,  # 相关问题\n",
    "        num_questions_and_answers,  # QA的数量\n",
    "        num_retrieved_evidences,  # 检索增强证据\n",
    "    )\n",
    "\n",
    "    # 拼接示例提示和用户问题提示\n",
    "    fresh_prompt = freshprompt_demo + freshprompt_question  # 将这两部分相加\n",
    "    # 前一部分是示例，后一部分是要问的问题。\n",
    "\n",
    "    # 调用大语言模型API获取答案\n",
    "    answer = call_llm_api(\n",
    "        fresh_prompt, model, temperature, max_tokens, chat_completions\n",
    "    )\n",
    "    return answer  # 返回生成的答案\n",
    "\n",
    "# 提取Link url\n",
    "def exact_link_url(question, url_count):\n",
    "    search_data = call_search_engine(question)\n",
    "    url_list = []\n",
    "\n",
    "    # 确认'questions_and_answers'字段存在并且是列表\n",
    "    if 'questions_and_answers' in search_data and isinstance(search_data['questions_and_answers'], list):\n",
    "        # 计算实际可用的结果数量\n",
    "        available_count = min(url_count, len(search_data['questions_and_answers']))\n",
    "\n",
    "        for i in range(available_count):\n",
    "            search_result = search_data['questions_and_answers'][i]\n",
    "            if \"link\" in search_result:\n",
    "                source = search_result[\"link\"]\n",
    "                url_list.append(source)\n",
    "    \n",
    "    return url_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question contains a valid premise.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# @markdown ---\n",
    "model_name = \"gpt-3.5-turbo\" #@param [\"gpt-4-0125-preview\", \"gpt-4-turbo-preview\", \"gpt-4-1106-preview\", \"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-instruct\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-0301\"]\n",
    "check_premise = True  # @param {type:\"boolean\"}\n",
    "# @markdown ### Ask your question here!\n",
    "\n",
    "# question = \"Who is the latest artist confirmed to be performing during the 2024 Grammys telecast?\"  # @param {type:\"string\"}\n",
    "question = \"What year is considered Albert Einstein's annus mirabilis?\"\n",
    "answer = call_freshprompt(model_name, question, check_premise=check_premise)\n",
    "\n",
    "# Directly output the answer\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.quora.com/What-caused-Einsteins-annus-mirabilis', 'https://www.reddit.com/r/Physics/comments/17f1m87/did_einsteins_post1905_publications_have_a/', 'https://brainly.com/question/8624807']\n"
     ]
    }
   ],
   "source": [
    "url_list = exact_link_url(question, url_count=3)\n",
    "print(url_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
