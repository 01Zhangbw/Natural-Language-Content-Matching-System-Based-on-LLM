{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cIMEmj9Esik",
        "outputId": "fe369166-5d1f-4501-f9fc-6b4f2c4a2d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in d:\\d\\python\\lib\\site-packages (1.30.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\d\\python\\lib\\site-packages (from openai) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\d\\python\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\d\\python\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\d\\python\\lib\\site-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in d:\\d\\python\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\d\\python\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\d\\python\\lib\\site-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\d\\python\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in d:\\d\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\d\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\d\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\d\\python\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in d:\\d\\python\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: colorama in d:\\d\\python\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: google-search-results in d:\\d\\python\\lib\\site-packages (2.4.2)\n",
            "Requirement already satisfied: requests in d:\\d\\python\\lib\\site-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Installing required Python packages\n",
        "\n",
        "\n",
        "!pip install openai\n",
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "wW3P9qyxHHU8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google in d:\\d\\python\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\d\\python\\lib\\site-packages (from google) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\d\\python\\lib\\site-packages (from beautifulsoup4->google) (2.5)\n"
          ]
        }
      ],
      "source": [
        "#@title Importing Python libraries and modules\n",
        "\n",
        "!pip install google\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import dateutil\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "from openai import OpenAI\n",
        "import tabulate\n",
        "import textwrap\n",
        "\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "current_date = datetime.datetime.now(\n",
        "        pytz.timezone(\"America/Los_Angeles\")\n",
        "    ).strftime(\"%B %d, %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "98YRRHnz0SGu"
      },
      "outputs": [],
      "source": [
        "#@title API keys\n",
        "\n",
        "\n",
        "# OpenAI's API key (sign up at https://platform.openai.com/signup to get $5 in\n",
        "# free credit that can be used during your first 3 months)\n",
        "\n",
        "# 设置API-KEY\n",
        "openai_api_key = \"sk-JnWHmZFfrx9mWDahm7pJhfDoQNON5zDtm4jabuapWyp09yll\"  # @param {type:\"string\"}\n",
        "openai_client = OpenAI(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
        ")\n",
        "\n",
        "# SerpApi's API key (sign up at https://serpapi.com/users/sign_up?plan=free for\n",
        "# a free plan with 100 searches/month)\n",
        "serpapi_api_key = \"608a172cd041ef113d8365d60d2129dfb80218fea80eb0c361f46ab4d91465b5\"  # @param {type:\"string\"}\n",
        "\n",
        "assert (\n",
        "    openai_api_key is not None and openai_api_key != \"\"\n",
        "), \"OpenAI's API key is not set\"\n",
        "assert (\n",
        "    serpapi_api_key is not None and serpapi_api_key != \"\"\n",
        "), \"SerpApi's API key is not set\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "7x4S8-FHHtK1"
      },
      "outputs": [],
      "source": [
        "# 调用LLM的API\n",
        "def call_llm_api(prompt, model, temperature, max_tokens, chat_completions=True):\n",
        "  # 参见https://platform.openai.com/docs/guides/gpt获取详细信息\n",
        "  if chat_completions:\n",
        "    # 调用聊天模式的API\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,  # 使用指定的模型\n",
        "        temperature=temperature,  # 设置生成文本的随机性\n",
        "        max_tokens=max_tokens,  # 设置生成文本的最大长度\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",  # 系统角色消息，用于设置助手的行为\n",
        "                \"content\": (\n",
        "                    \"You are a helpful assistant. Answer as concisely as\"\n",
        "                    f\" possible. Knowledge cutoff: {current_date}.\"  # 提供上下文和知识截断日期\n",
        "                ),\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": \"What's today's date?\"},  # 用户消息示例\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": f\"Today is {current_date} in Pacific Standard Time.\",  # 助手响应示例\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt},  # 实际用户提示消息\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content  # 返回生成的文本内容\n",
        "\n",
        "  else:\n",
        "    # 调用完成模式的API\n",
        "    response = openai_client.completions.create(\n",
        "        model=model,  # 使用指定的模型\n",
        "        temperature=temperature,  # 设置生成文本的随机性\n",
        "        max_tokens=max_tokens,  # 设置生成文本的最大长度\n",
        "        prompt=prompt,  # 实际用户提示\n",
        "    )\n",
        "    return response.choices[0].text  # 返回生成的文本内容\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "1wZfMlvj0i-Z"
      },
      "outputs": [],
      "source": [
        "# @title Function calling for the search engine\n",
        "\n",
        "# 调用搜索引擎\n",
        "def call_search_engine(query):\n",
        "  params = {\n",
        "    \"q\": query,\n",
        "    # \"location\": \"California, United States\",\n",
        "    \"hl\": \"en\",\n",
        "    \"gl\": \"us\",\n",
        "    \"google_domain\": \"google.com\",\n",
        "    \"api_key\": serpapi_api_key,\n",
        "\n",
        "  }\n",
        "\n",
        "  search = GoogleSearch(params)\n",
        "  return search.get_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "oQTRnGgcxC8h"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19112\\1033143825.py:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  n_days = int(re.search(\"(\\d+) days? ago\", d).group(1))\n"
          ]
        }
      ],
      "source": [
        "# @title Utility functions for FreshPrompt\n",
        "\n",
        "def is_date(string, fuzzy=False):\n",
        "  # Parse a string into a date and check its validity\n",
        "  try:\n",
        "      dateutil.parser.parse(string, fuzzy=fuzzy)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "\n",
        "\n",
        "def format_date(d):\n",
        "  # Standardize the date format for each search result\n",
        "  date = dateutil.parser.parse(current_date, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "  if d is None:\n",
        "    return None\n",
        "\n",
        "  for t in [\"second\", \"minute\", \"hour\"]:\n",
        "    if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
        "      return date\n",
        "\n",
        "  t = \"day\"\n",
        "  if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
        "    n_days = int(re.search(\"(\\d+) days? ago\", d).group(1))\n",
        "    return (\n",
        "        datetime.datetime.strptime(date, \"%b %d, %Y\")\n",
        "        - datetime.timedelta(days=n_days)\n",
        "    ).strftime(\"%b %d, %Y\")\n",
        "\n",
        "  try:\n",
        "    return dateutil.parser.parse(d, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "  except ValueError:\n",
        "    for x in d.split():\n",
        "      if is_date(x):\n",
        "        return dateutil.parser.parse(x, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "\n",
        "# 解析网页\n",
        "def extract_source_webpage(link):\n",
        "  # Extract source webpage\n",
        "  return (\n",
        "      link.strip()\n",
        "      .replace(\"https://www.\", \"\")\n",
        "      .replace(\"http://www.\", \"\")\n",
        "      .replace(\"https://\", \"\")\n",
        "      .replace(\"http://\", \"\")\n",
        "      .split(\"/\")[0]\n",
        "  )\n",
        "\n",
        "\n",
        "def simplify_displayed_link(displayed_link):\n",
        "  # Simplify displayed link\n",
        "  if displayed_link is None:\n",
        "    return None\n",
        "  return extract_source_webpage(displayed_link.split(' › ')[0])\n",
        "\n",
        "# 格式化搜索结果\n",
        "def format_search_results(search_data, title_field=None, highlight_field=None):\n",
        "  # Standardize search results as shown in Figure 3 (left) in the paper\n",
        "  field = 'snippet_highlighted_words'\n",
        "  if field in search_data and isinstance(search_data[field], list):\n",
        "    search_data[field] = ' | '.join(search_data[field])\n",
        "\n",
        "  field = 'displayed_link'\n",
        "  if field in search_data:\n",
        "    search_data[field] = simplify_displayed_link(search_data[field])\n",
        "\n",
        "  # edge case 1\n",
        "  if search_data.get('type') == 'local_time':\n",
        "    source = search_data.get('displayed_link')\n",
        "    date = format_date(search_data.get('date'))\n",
        "    title = search_data.get('title')\n",
        "\n",
        "    snippet = search_data.get('snippet')\n",
        "    if snippet is None and 'result' in search_data:\n",
        "      if 'extensions' in search_data and isinstance(\n",
        "          search_data['extensions'], list\n",
        "      ):\n",
        "        snippet = '\\n\\t'.join(\n",
        "            [search_data['result']] + search_data['extensions']\n",
        "        )\n",
        "      else:\n",
        "        snippet = search_data['result']\n",
        "\n",
        "    highlight = search_data.get('snippet_highlighted_words')\n",
        "    if highlight is None and 'result' in search_data:\n",
        "      highlight = search_data['result']\n",
        "\n",
        "  # edge case 2\n",
        "  elif 'type' in search_data and search_data['type'] == 'population_result':\n",
        "    source = search_data.get('displayed_link')\n",
        "    if source is None and 'sources' in search_data:\n",
        "      if (\n",
        "          isinstance(search_data['sources'], list)\n",
        "          and 'link' in search_data['sources'][0]\n",
        "      ):\n",
        "        source = extract_source_webpage(search_data['sources'][0]['link'])\n",
        "\n",
        "    date = format_date(search_data.get('date'))\n",
        "    if date is None and 'year' in search_data:\n",
        "      date = format_date(search_data['year'])\n",
        "\n",
        "    title = search_data.get('title')\n",
        "\n",
        "    snippet = search_data.get('snippet')\n",
        "    if snippet is None and 'population' in search_data:\n",
        "      if 'place' in search_data:\n",
        "        snippet = '\\n\\t'.join(\n",
        "            [\n",
        "                f\"{search_data['place']} / Population\",\n",
        "            ]\n",
        "            + [\n",
        "                search_data['population'],\n",
        "            ]\n",
        "        )\n",
        "      else:\n",
        "        snippet = search_data['population']\n",
        "\n",
        "    highlight = search_data.get('snippet_highlighted_words')\n",
        "    if highlight is None and 'population' in search_data:\n",
        "      highlight = search_data['population']\n",
        "\n",
        "  else:\n",
        "    source = search_data.get('displayed_link')\n",
        "    date = format_date(search_data.get('date'))\n",
        "    title = (\n",
        "        search_data.get('title')\n",
        "        if title_field is None\n",
        "        else search_data.get(title_field)\n",
        "    )\n",
        "    highlight = (\n",
        "        search_data.get('snippet_highlighted_words')\n",
        "        if highlight_field is None\n",
        "        else search_data.get(highlight_field)\n",
        "    )\n",
        "    snippet = search_data.get('snippet', '')\n",
        "\n",
        "    if 'rich_snippet' in search_data:\n",
        "      for key in ['top', 'bottom']:\n",
        "        if (\n",
        "            key in search_data['rich_snippet']\n",
        "            and 'extensions' in search_data['rich_snippet'][key]\n",
        "        ):\n",
        "          snippet = '\\n\\t'.join(\n",
        "              [snippet] + search_data['rich_snippet'][key]['extensions']\n",
        "          )\n",
        "\n",
        "    if 'list' in search_data:\n",
        "      assert isinstance(search_data['list'], list)\n",
        "      snippet = '\\n\\t'.join([snippet] + search_data['list'])\n",
        "\n",
        "    if 'contents' in search_data and 'table' in search_data['contents']:\n",
        "      tbl = search_data['contents']['table']\n",
        "      assert isinstance(tbl, list)\n",
        "      snippet += '\\n'\n",
        "      for row in tbl:\n",
        "        snippet += f'\\n{\",\".join(row)}'\n",
        "\n",
        "    if snippet is not None and snippet.strip() == '':\n",
        "      snippet = None\n",
        "# 返回成固定的格式\n",
        "  return {\n",
        "      'source': source,\n",
        "      'date': date,\n",
        "      'title': title,\n",
        "      'snippet': snippet,\n",
        "      'highlight': highlight,\n",
        "  }\n",
        "\n",
        "# 格式化知识图谱\n",
        "\n",
        "def format_knowledge_graph(search_data):\n",
        "  # Standardize knowledge graphs as shown in Figure 3 (left) in the paper\n",
        "  source = None\n",
        "  if \"source\" in search_data and \"link\" in search_data[\"source\"]:\n",
        "    source = extract_source_webpage(search_data[\"source\"][\"link\"])\n",
        "\n",
        "  date = None\n",
        "\n",
        "  title = None\n",
        "  if \"title\" in search_data:\n",
        "    title = search_data[\"title\"]\n",
        "    if \"type\" in search_data:\n",
        "      title += f\"\\n\\t{search_data['type']}\"\n",
        "\n",
        "  snippet = \"\"\n",
        "  for field in search_data:\n",
        "    if (\n",
        "        (field not in [\"title\", \"type\", \"kgmid\"])\n",
        "        and (\"_link\" not in field)\n",
        "        and (\"_stick\" not in field)\n",
        "        and isinstance(search_data[field], str)\n",
        "        and not search_data[field].startswith(\"http\")\n",
        "    ):\n",
        "      snippet += f\"\\n\\t{field}: {search_data[field]}\"\n",
        "\n",
        "  if snippet.strip() == \"\":\n",
        "    snippet = None\n",
        "  else:\n",
        "    snippet = snippet.strip()\n",
        "\n",
        "  highlight = None\n",
        "\n",
        "  return {\n",
        "      \"source\": source,\n",
        "      \"date\": date,\n",
        "      \"title\": title,\n",
        "      \"snippet\": snippet,\n",
        "      \"highlight\": highlight,\n",
        "  }\n",
        "\n",
        "\n",
        "# 格式化 Q and A\n",
        "def format_questions_and_answers(search_data):\n",
        "  # Standardize questions and answers as shown in Figure 3 (left) in the paper\n",
        "  source = None\n",
        "  if \"link\" in search_data:\n",
        "    source = extract_source_webpage(search_data[\"link\"])\n",
        "\n",
        "  date = None\n",
        "\n",
        "  title = None\n",
        "  if \"question\" in search_data:\n",
        "    title = search_data[\"question\"]\n",
        "\n",
        "  snippet = None\n",
        "  if \"answer\" in search_data:\n",
        "    snippet = search_data[\"answer\"]\n",
        "\n",
        "  highlight = None\n",
        "\n",
        "  return {\n",
        "      \"source\": source,\n",
        "      \"date\": date,\n",
        "      \"title\": title,\n",
        "      \"snippet\": snippet,\n",
        "      \"highlight\": highlight,\n",
        "  }\n",
        "\n",
        "# 对freshprompt进行格式化\n",
        "def freshprompt_format(\n",
        "    question,\n",
        "    search_data,\n",
        "    reasoning_and_answer,\n",
        "    num_organic_results,\n",
        "    num_related_questions,\n",
        "    num_questions_and_answers,\n",
        "    num_retrieved_evidences,\n",
        "):\n",
        "  \"\"\"Build FreshPrompt for each question\n",
        "\n",
        "  Args:\n",
        "    question: The question to process.\n",
        "    search_data: Search data.\n",
        "    reasoning_and_answer: The reasoning and answer.\n",
        "    num_organic_results: Number of organic results to keep.\n",
        "    num_related_questions: Number of related questions to keep.\n",
        "    num_questions_and_answers: Number of questions and answers to keep.\n",
        "    num_retrieved_evidences: Number of retrieved evidences to keep.\n",
        "\n",
        "  Returns:\n",
        "    A prompt that incorporates retrieved evidences for each question.\n",
        "  \"\"\"\n",
        "\n",
        "  df = pd.DataFrame(columns=['source', 'date', 'title', 'snippet', 'highlight'])\n",
        "\n",
        "  # Organic results\n",
        "  organic_results = [None] * num_organic_results\n",
        "  for k in range(num_organic_results):\n",
        "    if (\n",
        "        'organic_results' in search_data\n",
        "        and len(search_data['organic_results']) > k\n",
        "    ):\n",
        "      organic_results[k] = format_search_results(\n",
        "          search_data['organic_results'][k]\n",
        "      )\n",
        "    else:\n",
        "      organic_results[k] = format_search_results({})\n",
        "\n",
        "  for d in organic_results[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Related questions\n",
        "  related_questions = [None] * num_related_questions\n",
        "  for k in range(num_related_questions):\n",
        "    if (\n",
        "        'related_questions' in search_data\n",
        "        and len(search_data['related_questions']) > k\n",
        "    ):\n",
        "      related_questions[k] = format_search_results(\n",
        "          search_data['related_questions'][k], title_field='question'\n",
        "      )\n",
        "    else:\n",
        "      related_questions[k] = format_search_results({})\n",
        "\n",
        "  for d in related_questions[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Questions and Answers\n",
        "  questions_and_answers = [None] * num_questions_and_answers\n",
        "  for k in range(num_questions_and_answers):\n",
        "    if (\n",
        "        'questions_and_answers' in search_data\n",
        "        and len(search_data['questions_and_answers']) > k\n",
        "    ):\n",
        "      questions_and_answers[k] = format_questions_and_answers(\n",
        "          search_data['questions_and_answers'][k]\n",
        "      )\n",
        "    else:\n",
        "      questions_and_answers[k] = format_questions_and_answers({})\n",
        "\n",
        "  for d in questions_and_answers[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Knowledge graph\n",
        "  knowledge_graph = None\n",
        "  if 'knowledge_graph' in search_data:\n",
        "    knowledge_graph = format_knowledge_graph(search_data['knowledge_graph'])\n",
        "  else:\n",
        "    knowledge_graph = format_knowledge_graph({})\n",
        "  df = pd.concat([df, pd.DataFrame([knowledge_graph])], ignore_index=True)\n",
        "\n",
        "  # Answer box\n",
        "  answer_box = None\n",
        "  if 'answer_box' in search_data:\n",
        "    answer_box = format_search_results(\n",
        "        search_data['answer_box'], highlight_field='answer'\n",
        "    )\n",
        "  else:\n",
        "    answer_box = format_search_results({})\n",
        "  df = pd.concat([df, pd.DataFrame([answer_box])], ignore_index=True)\n",
        "\n",
        "  # Sort by date\n",
        "  df['date'] = df['date'].apply(lambda x: format_date(x))\n",
        "  df['datetime'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "  df = df.sort_values(by='datetime', na_position='first')\n",
        "  df.replace({pd.NaT: None}, inplace=True)\n",
        "  df = df.dropna(how='all')\n",
        "\n",
        "  # Select top_k supporting evidences overall\n",
        "  evidences = []\n",
        "\n",
        "  for _, row in df.tail(num_retrieved_evidences).iterrows():\n",
        "    evidences.append(\n",
        "        f\"\"\"\\n\\nsource: {row['source']}\\ndate: {row['date']}\\ntitle: {row['title']}\\nsnippet: {row['snippet']}\\nhighlight: {row['highlight']}\"\"\"\n",
        "    )\n",
        "\n",
        "  return (\n",
        "      ''.join(\n",
        "          [\n",
        "              f'\\n\\n\\nquery: {question}',\n",
        "          ]\n",
        "          + evidences\n",
        "      )\n",
        "      + f'\\n\\nquestion: {question}{reasoning_and_answer}'\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "xmQZYfPD3sxL"
      },
      "outputs": [],
      "source": [
        "#@title Demonstration examples\n",
        "\n",
        "\n",
        "demo_questions = [\n",
        "    \"What year is considered Albert Einstein's annus mirabilis?\",\n",
        "    \"Which photographer took the most expensive photograph in the world?\",\n",
        "    \"How many days are left until the 2023 Grammy Awards?\",\n",
        "    \"How many years ago did the Boxing Day Tsunami happen?\",\n",
        "    (\n",
        "        \"When did Amazon become the first publicly traded company to exceed a\"\n",
        "        \" market value of $3 trillion?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "concise_demo_reasonings_and_answers = [\n",
        "    (\n",
        "        \"1905 is considered Albert Einstein's annus mirabilis, his miraculous\"\n",
        "        \" year.\"\n",
        "    ),\n",
        "    (\n",
        "        'The most expensive photograph in the world is \"Le Violon d\\'Ingres\".'\n",
        "        \" The photograph was created by Man Ray.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The 2023 Grammy Awards ceremony was held on February 5, 2023. Thus,\"\n",
        "        \" the ceremony has already taken place.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The disaster occurred on December 26, 2004. Thus, it happened 19 years\"\n",
        "        \" ago.\"\n",
        "    ),\n",
        "    \"Amazon's market capitalization has never exceeded $3 trillion.\",\n",
        "]\n",
        "\n",
        "verbose_demo_reasonings_and_answers = [\n",
        "    (\n",
        "        \"In the year of 1905, Albert Einstein published four groundbreaking\"\n",
        "        \" papers that revolutionized scientific understanding of the universe.\"\n",
        "        \" Thus, scientists call 1905 Albert Einstein's annus mirabilis — his\"\n",
        "        \" year of miracles.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Man Ray's famed \\\"Le Violon d'Ingres\\\" became the most expensive\"\n",
        "        \" photograph ever to sell at auction, sold for $12.4 million on May\"\n",
        "        \" 14th, 2022 at Christie's New York. The black and white image, taken\"\n",
        "        \" in 1924 by the American surrealist artist, transforms a woman's naked\"\n",
        "        \" body into a violin by overlaying the picture of her back with\"\n",
        "        \" f-holes. Thus, Man Ray is the photographer who took the most\"\n",
        "        \" expensive photograph in the world.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The 2023 Grammy Awards, officially known as the 65th Annual Grammy\"\n",
        "        \" Awards ceremony, was held in Los Angeles on February 5, 2023. Thus,\"\n",
        "        \" the event has already taken place.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The Boxing Day Tsunami refers to the 2004 Indian Ocean earthquake and\"\n",
        "        \" tsunami, which is one of the deadliest natural disasters in recorded\"\n",
        "        \" history, killing an estimated 230,000 people across 14 countries. The\"\n",
        "        \" disaster occurred on December 26, 2004, which is 19 years ago.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Amazon's market capitalization hit a peak of roughly $1.9 trillion in\"\n",
        "        \" July 2021. In 2022, Amazon became the first public company ever to\"\n",
        "        \" lose $1 trillion in market value. Thus, Amazon's market value has\"\n",
        "        \" never exceeded $3 trillion. In fact, Apple became the first publicly\"\n",
        "        \" traded U.S. company to exceed a market value of $3 trillion in\"\n",
        "        \" January 2022.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "prefix = (\n",
        "    f\"\\nanswer: As of today {current_date}, the most up-to-date and relevant\"\n",
        "    \" information regarding this query is as follows. \"\n",
        ")\n",
        "\n",
        "concise_demo_reasonings_and_answers = [\n",
        "    prefix + x for x in concise_demo_reasonings_and_answers\n",
        "]\n",
        "verbose_demo_reasonings_and_answers = [\n",
        "    prefix + x for x in verbose_demo_reasonings_and_answers\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "MS6fKTK-A8bY"
      },
      "outputs": [],
      "source": [
        "#@title Retrieving search data for demonstration examples\n",
        "\n",
        "\n",
        "demo_search_data = [call_search_engine(q) for q in demo_questions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "fAcuImw5EP5T"
      },
      "outputs": [],
      "source": [
        "# 调用 freshprompt 函数\n",
        "\n",
        "def call_freshprompt(model, question, check_premise=False, verbose=False):\n",
        "  # 初始化模型参数\n",
        "  temperature = 0.0  # 模型的温度参数，影响生成结果的随机性\n",
        "  max_tokens = 256  # 最大生成的token数量\n",
        "  chat_completions = True  # 是否使用对话完成模式\n",
        "\n",
        "  # 根据模型类型设置不同的参数\n",
        "  if model.startswith('gpt-4'):\n",
        "    num_organic_results = 15  # 自然搜索结果数量\n",
        "    num_related_questions = 3  # 相关问题数量\n",
        "    num_questions_and_answers = 3  # 问答对数量\n",
        "    num_retrieved_evidences = 15  # 检索到的证据数量\n",
        "  else:\n",
        "    num_organic_results = 15\n",
        "    num_related_questions = 2\n",
        "    num_questions_and_answers = 2\n",
        "    num_retrieved_evidences = 5\n",
        "\n",
        "  # 选择推理和回答示例的格式\n",
        "  if verbose:\n",
        "    demo_reasonings_and_answers = verbose_demo_reasonings_and_answers\n",
        "  else:\n",
        "    demo_reasonings_and_answers = concise_demo_reasonings_and_answers\n",
        "\n",
        "  # 生成示例提示\n",
        "  demo_prompts = []\n",
        "  for q, s, ra in zip(\n",
        "      demo_questions, demo_search_data, concise_demo_reasonings_and_answers\n",
        "  ):\n",
        "      demo_prompts.append(\n",
        "      freshprompt_format(\n",
        "          q,  # 示例问题\n",
        "          s,  # 搜索数据\n",
        "          ra,  # 推理和回答\n",
        "          num_organic_results,\n",
        "          num_related_questions,\n",
        "          num_questions_and_answers,\n",
        "          num_retrieved_evidences,\n",
        "      )\n",
        "      )\n",
        "\n",
        "  freshprompt_demo = ''.join(demo_prompts).strip()  # 将所有示例提示拼接成一个字符串\n",
        "\n",
        "  # 根据是否检查前提来设置后缀\n",
        "  if check_premise:\n",
        "    suffix = (\n",
        "        \"\\nPlease check if the question contains a valid premise before\"\n",
        "        \" answering.\\nanswer: \"\n",
        "    )\n",
        "  else:\n",
        "    suffix = \"\\nanswer: \"\n",
        "\n",
        "  # 生成用户问题的提示\n",
        "  freshprompt_question = freshprompt_format(\n",
        "      question,  # 用户问题\n",
        "      call_search_engine(question),  # 调用搜索引擎获取相关数据\n",
        "      suffix,  # 后缀\n",
        "      num_organic_results,\n",
        "      num_related_questions,\n",
        "      num_questions_and_answers,\n",
        "      num_retrieved_evidences,\n",
        "  )\n",
        "\n",
        "  # 拼接示例提示和用户问题提示\n",
        "  fresh_prompt = freshprompt_demo + freshprompt_question\n",
        "\n",
        "  # 调用大语言模型API获取答案\n",
        "  answer = call_llm_api(\n",
        "      fresh_prompt, model, temperature, max_tokens, chat_completions\n",
        "  )\n",
        "  return answer  # 返回生成的答案\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "call_llm_api() got an unexpected keyword argument 'check_premise'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m现在的中国国家主席是胡锦涛。\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m check_premise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_premise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_premise\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mTypeError\u001b[0m: call_llm_api() got an unexpected keyword argument 'check_premise'"
          ]
        }
      ],
      "source": [
        "question = \"现在的中国国家主席是胡锦涛。\"\n",
        "check_premise=False\n",
        "answer = call_llm_api(model_name,question, check_premise=check_premise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e341fa1398f1464bb4dddee86365410d",
            "cfbb04a5dce540949c96f46290ba2273",
            "86c6583dc7fc48ebbb94665fd04dcfbe",
            "b0ee2576f40a465f96141e5dfe28de39",
            "36edaa5501b04ddcbdaa7aa009a82fc3"
          ]
        },
        "id": "QB_Cm9mjG3OD",
        "outputId": "76125060-f939-4765-cdbe-ffd84610a2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The statement in the question is invalid. As of May 26, 2024, Xi Jinping is the President of China, not Hu Jintao.\n"
          ]
        }
      ],
      "source": [
        "#@title FreshPrompt\n",
        "\n",
        "# @markdown ---\n",
        "model_name = \"gpt-3.5-turbo\" #@param [\"gpt-4-0125-preview\", \"gpt-4-turbo-preview\", \"gpt-4-1106-preview\", \"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-instruct\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-0301\"]\n",
        "check_premise = True  # @param {type:\"boolean\"}\n",
        "# @markdown ### Ask your question here!\n",
        "\n",
        "# question = \"Who is the latest artist confirmed to be performing during the 2024 Grammys telecast?\"  # @param {type:\"string\"}\n",
        "question = \"现在的中国国家主席是胡锦涛。\"\n",
        "answer = call_freshprompt(model_name, question, check_premise=check_premise)\n",
        "\n",
        "# Directly output the answer\n",
        "print(answer)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36edaa5501b04ddcbdaa7aa009a82fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c6583dc7fc48ebbb94665fd04dcfbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b0ee2576f40a465f96141e5dfe28de39": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_36edaa5501b04ddcbdaa7aa009a82fc3",
            "msg_id": "",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "\n",
                  "As of January 28, 2024, the latest artist confirmed to be performing during the 2024 Grammys telecast is Joni Mitchell.\n"
                ]
              }
            ]
          }
        },
        "cfbb04a5dce540949c96f46290ba2273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e341fa1398f1464bb4dddee86365410d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "SHOW ANSWER",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cfbb04a5dce540949c96f46290ba2273",
            "style": "IPY_MODEL_86c6583dc7fc48ebbb94665fd04dcfbe",
            "tooltip": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
