{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cIMEmj9Esik",
        "outputId": "fe369166-5d1f-4501-f9fc-6b4f2c4a2d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in d:\\d\\python\\lib\\site-packages (1.30.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\d\\python\\lib\\site-packages (from openai) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\d\\python\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\d\\python\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\d\\python\\lib\\site-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in d:\\d\\python\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\d\\python\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\d\\python\\lib\\site-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\d\\python\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in d:\\d\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\d\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\d\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\d\\python\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in d:\\d\\python\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: colorama in d:\\d\\python\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: google-search-results in d:\\d\\python\\lib\\site-packages (2.4.2)\n",
            "Requirement already satisfied: requests in d:\\d\\python\\lib\\site-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\d\\python\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "#@title Installing required Python packages\n",
        "\n",
        "\n",
        "!pip install openai\n",
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "wW3P9qyxHHU8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google in d:\\d\\python\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\d\\python\\lib\\site-packages (from google) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\d\\python\\lib\\site-packages (from beautifulsoup4->google) (2.5)\n"
          ]
        }
      ],
      "source": [
        "#@title Importing Python libraries and modules\n",
        "\n",
        "!pip install google\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import dateutil\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "from openai import OpenAI\n",
        "import tabulate\n",
        "import textwrap\n",
        "\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "current_date = datetime.datetime.now(\n",
        "        pytz.timezone(\"America/Los_Angeles\")\n",
        "    ).strftime(\"%B %d, %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "98YRRHnz0SGu"
      },
      "outputs": [],
      "source": [
        "#@title API keys\n",
        "\n",
        "\n",
        "# OpenAI's API key (sign up at https://platform.openai.com/signup to get $5 in\n",
        "# free credit that can be used during your first 3 months)\n",
        "\n",
        "# 设置API-KEY\n",
        "openai_api_key = \"sk-JnWHmZFfrx9mWDahm7pJhfDoQNON5zDtm4jabuapWyp09yll\"  # @param {type:\"string\"}\n",
        "openai_client = OpenAI(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
        ")\n",
        "\n",
        "# SerpApi's API key (sign up at https://serpapi.com/users/sign_up?plan=free for\n",
        "# a free plan with 100 searches/month)\n",
        "serpapi_api_key = \"608a172cd041ef113d8365d60d2129dfb80218fea80eb0c361f46ab4d91465b5\"  # @param {type:\"string\"}\n",
        "\n",
        "assert (\n",
        "    openai_api_key is not None and openai_api_key != \"\"\n",
        "), \"OpenAI's API key is not set\"\n",
        "assert (\n",
        "    serpapi_api_key is not None and serpapi_api_key != \"\"\n",
        "), \"SerpApi's API key is not set\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "7x4S8-FHHtK1"
      },
      "outputs": [],
      "source": [
        "# 调用LLM的API函数\n",
        "def call_llm_api(prompt, model, temperature, max_tokens, chat_completions=True):\n",
        "    \"\"\"\n",
        "    调用LLM（大型语言模型）的API以生成响应文本。\n",
        "\n",
        "    参数：\n",
        "    - prompt: 用户输入的提示文本\n",
        "    - model: 要使用的语言模型\n",
        "    - temperature: 设置生成文本的随机性（温度参数）\n",
        "    - max_tokens: 设置生成文本的最大长度\n",
        "    - chat_completions: 指定是否使用聊天模式，默认为True\n",
        "\n",
        "    返回：\n",
        "    - 生成的响应文本\n",
        "    \"\"\"\n",
        "\n",
        "    # 参见OpenAI文档获取详细信息：https://platform.openai.com/docs/guides/gpt\n",
        "    if chat_completions:\n",
        "        # 调用聊天模式的API\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=model,  # 使用指定的模型\n",
        "            temperature=temperature,  # 设置生成文本的随机性\n",
        "            max_tokens=max_tokens,  # 设置生成文本的最大长度\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",  # 系统角色消息，用于设置助手的行为\n",
        "                    \"content\": (\n",
        "                        \"You are a helpful assistant. Answer as concisely as\"\n",
        "                        f\" possible. Knowledge cutoff: {current_date}.\"  # 提供上下文和知识截断日期\n",
        "                    ),\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": \"What's today's date?\"},  # 用户消息示例\n",
        "                {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": f\"Today is {current_date} in Pacific Standard Time.\",  # 助手响应示例\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": prompt},  # 实际用户提示消息\n",
        "            ],\n",
        "        )\n",
        "        return response.choices[0].message.content  # 返回生成的文本内容\n",
        "\n",
        "    else:\n",
        "        # 调用完成模式的API\n",
        "        response = openai_client.completions.create(\n",
        "            model=model,  # 使用指定的模型\n",
        "            temperature=temperature,  # 设置生成文本的随机性\n",
        "            max_tokens=max_tokens,  # 设置生成文本的最大长度\n",
        "            prompt=prompt,  # 实际用户提示\n",
        "        )\n",
        "        return response.choices[0].text  # 返回生成的文本内容\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "1wZfMlvj0i-Z"
      },
      "outputs": [],
      "source": [
        "# @title Function calling for the search engine\n",
        "\n",
        "# 调用搜索引擎\n",
        "def call_search_engine(query):\n",
        "  params = {\n",
        "    \"q\": query,\n",
        "    # \"location\": \"California, United States\",\n",
        "    \"hl\": \"en\",\n",
        "    \"gl\": \"us\",\n",
        "    \"google_domain\": \"google.com\",\n",
        "    \"api_key\": serpapi_api_key,\n",
        "\n",
        "  }\n",
        "\n",
        "  search = GoogleSearch(params)\n",
        "  return search.get_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "oQTRnGgcxC8h"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12776\\1033143825.py:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  n_days = int(re.search(\"(\\d+) days? ago\", d).group(1))\n"
          ]
        }
      ],
      "source": [
        "# @title Utility functions for FreshPrompt\n",
        "\n",
        "def is_date(string, fuzzy=False):\n",
        "  # Parse a string into a date and check its validity\n",
        "  try:\n",
        "      dateutil.parser.parse(string, fuzzy=fuzzy)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "\n",
        "\n",
        "def format_date(d):\n",
        "  # Standardize the date format for each search result\n",
        "  date = dateutil.parser.parse(current_date, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "  if d is None:\n",
        "    return None\n",
        "\n",
        "  for t in [\"second\", \"minute\", \"hour\"]:\n",
        "    if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
        "      return date\n",
        "\n",
        "  t = \"day\"\n",
        "  if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
        "    n_days = int(re.search(\"(\\d+) days? ago\", d).group(1))\n",
        "    return (\n",
        "        datetime.datetime.strptime(date, \"%b %d, %Y\")\n",
        "        - datetime.timedelta(days=n_days)\n",
        "    ).strftime(\"%b %d, %Y\")\n",
        "\n",
        "  try:\n",
        "    return dateutil.parser.parse(d, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "  except ValueError:\n",
        "    for x in d.split():\n",
        "      if is_date(x):\n",
        "        return dateutil.parser.parse(x, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "\n",
        "# 解析网页\n",
        "def extract_source_webpage(link):\n",
        "  # Extract source webpage\n",
        "  return (\n",
        "      link.strip()\n",
        "      .replace(\"https://www.\", \"\")\n",
        "      .replace(\"http://www.\", \"\")\n",
        "      .replace(\"https://\", \"\")\n",
        "      .replace(\"http://\", \"\")\n",
        "      .split(\"/\")[0]\n",
        "  )\n",
        "\n",
        "\n",
        "def simplify_displayed_link(displayed_link):\n",
        "  # Simplify displayed link\n",
        "  if displayed_link is None:\n",
        "    return None\n",
        "  return extract_source_webpage(displayed_link.split(' › ')[0])\n",
        "\n",
        "# 格式化搜索结果\n",
        "def format_search_results(search_data, title_field=None, highlight_field=None):\n",
        "  # Standardize search results as shown in Figure 3 (left) in the paper\n",
        "  '''\n",
        "    参数：\n",
        "    - search_data: 包含搜索结果数据的字典\n",
        "    - title_field: 可选，指定用于标题的字段\n",
        "    - highlight_field: 可选，指定用于高亮显示的字段\n",
        "\n",
        "    返回：\n",
        "    - 一个包含格式化后的搜索结果的字典\n",
        "  '''\n",
        "  # 标准化字段\"snippet_highlighted_words\"\n",
        "  field = 'snippet_highlighted_words'\n",
        "  if field in search_data and isinstance(search_data[field], list):\n",
        "    search_data[field] = ' | '.join(search_data[field])\n",
        "  # 标准化字段\"displayed_link\"\n",
        "  field = 'displayed_link'\n",
        "  if field in search_data:\n",
        "    search_data[field] = simplify_displayed_link(search_data[field])\n",
        "\n",
        "  # edge case 1：处理特定类型\"local_time\"的边缘情况\n",
        "  if search_data.get('type') == 'local_time':\n",
        "    source = search_data.get('displayed_link')\n",
        "    date = format_date(search_data.get('date'))\n",
        "    title = search_data.get('title')\n",
        "\n",
        "    snippet = search_data.get('snippet')\n",
        "    if snippet is None and 'result' in search_data:\n",
        "      if 'extensions' in search_data and isinstance(\n",
        "          search_data['extensions'], list\n",
        "      ):\n",
        "        snippet = '\\n\\t'.join(\n",
        "            [search_data['result']] + search_data['extensions']\n",
        "        )\n",
        "      else:\n",
        "        snippet = search_data['result']\n",
        "\n",
        "    highlight = search_data.get('snippet_highlighted_words')\n",
        "    if highlight is None and 'result' in search_data:\n",
        "      highlight = search_data['result']\n",
        "\n",
        "  # edge case 2：处理特定类型\"population_result\"的边缘情况\n",
        "  elif 'type' in search_data and search_data['type'] == 'population_result':\n",
        "    source = search_data.get('displayed_link')\n",
        "    if source is None and 'sources' in search_data:\n",
        "      if (\n",
        "          isinstance(search_data['sources'], list)\n",
        "          and 'link' in search_data['sources'][0]\n",
        "      ):\n",
        "        source = extract_source_webpage(search_data['sources'][0]['link'])\n",
        "\n",
        "    date = format_date(search_data.get('date'))\n",
        "    if date is None and 'year' in search_data:\n",
        "      date = format_date(search_data['year'])\n",
        "\n",
        "    title = search_data.get('title')\n",
        "\n",
        "    snippet = search_data.get('snippet')\n",
        "    if snippet is None and 'population' in search_data:\n",
        "      if 'place' in search_data:\n",
        "        snippet = '\\n\\t'.join(\n",
        "            [\n",
        "                f\"{search_data['place']} / Population\",\n",
        "            ]\n",
        "            + [\n",
        "                search_data['population'],\n",
        "            ]\n",
        "        )\n",
        "      else:\n",
        "        snippet = search_data['population']\n",
        "\n",
        "    highlight = search_data.get('snippet_highlighted_words')\n",
        "    if highlight is None and 'population' in search_data:\n",
        "      highlight = search_data['population']\n",
        "\n",
        "# 处理其他类型的情况\n",
        "  else:\n",
        "    source = search_data.get('displayed_link')\n",
        "    date = format_date(search_data.get('date'))\n",
        "    title = (\n",
        "        search_data.get('title')\n",
        "        if title_field is None\n",
        "        else search_data.get(title_field)\n",
        "    )\n",
        "    highlight = (\n",
        "        search_data.get('snippet_highlighted_words')\n",
        "        if highlight_field is None\n",
        "        else search_data.get(highlight_field)\n",
        "    )\n",
        "    snippet = search_data.get('snippet', '')\n",
        "    # 处理'rich_snippet'字段\n",
        "    if 'rich_snippet' in search_data:\n",
        "      for key in ['top', 'bottom']:\n",
        "        if (\n",
        "            key in search_data['rich_snippet']\n",
        "            and 'extensions' in search_data['rich_snippet'][key]\n",
        "        ):\n",
        "          snippet = '\\n\\t'.join(\n",
        "              [snippet] + search_data['rich_snippet'][key]['extensions']\n",
        "          )\n",
        "    # 处理\"list\"字段\n",
        "    if 'list' in search_data:\n",
        "      assert isinstance(search_data['list'], list)\n",
        "      snippet = '\\n\\t'.join([snippet] + search_data['list'])\n",
        "    # 处理\"contents\"字段中的table\n",
        "    if 'contents' in search_data and 'table' in search_data['contents']:\n",
        "      tbl = search_data['contents']['table']\n",
        "      assert isinstance(tbl, list)\n",
        "      snippet += '\\n'\n",
        "      for row in tbl:\n",
        "        snippet += f'\\n{\",\".join(row)}'\n",
        "    # 如果snippet是空白字符串，将其设置为None\n",
        "    if snippet is not None and snippet.strip() == '':\n",
        "      snippet = None\n",
        "# 返回成固定的格式\n",
        "  return {\n",
        "      'source': source,\n",
        "      'date': date,\n",
        "      'title': title,\n",
        "      'snippet': snippet,\n",
        "      'highlight': highlight,\n",
        "  }\n",
        "\n",
        "# 格式化知识图谱\n",
        "def format_knowledge_graph(search_data):\n",
        "  # Standardize knowledge graphs as shown in Figure 3 (left) in the paper\n",
        "  source = None\n",
        "  if \"source\" in search_data and \"link\" in search_data[\"source\"]:\n",
        "    source = extract_source_webpage(search_data[\"source\"][\"link\"])\n",
        "\n",
        "  date = None\n",
        "\n",
        "  title = None\n",
        "  if \"title\" in search_data:\n",
        "    title = search_data[\"title\"]\n",
        "    if \"type\" in search_data:\n",
        "      title += f\"\\n\\t{search_data['type']}\"\n",
        "\n",
        "  snippet = \"\"\n",
        "  for field in search_data:\n",
        "    if (\n",
        "        (field not in [\"title\", \"type\", \"kgmid\"])\n",
        "        and (\"_link\" not in field)\n",
        "        and (\"_stick\" not in field)\n",
        "        and isinstance(search_data[field], str)\n",
        "        and not search_data[field].startswith(\"http\")\n",
        "    ):\n",
        "      snippet += f\"\\n\\t{field}: {search_data[field]}\"\n",
        "\n",
        "  if snippet.strip() == \"\":\n",
        "    snippet = None\n",
        "  else:\n",
        "    snippet = snippet.strip()\n",
        "\n",
        "  highlight = None\n",
        "\n",
        "  return {\n",
        "      \"source\": source,\n",
        "      \"date\": date,\n",
        "      \"title\": title,\n",
        "      \"snippet\": snippet,\n",
        "      \"highlight\": highlight,\n",
        "  }\n",
        "\n",
        "\n",
        "# 格式化 Q and A\n",
        "def format_questions_and_answers(search_data):\n",
        "  # Standardize questions and answers as shown in Figure 3 (left) in the paper\n",
        "  source = None\n",
        "  if \"link\" in search_data:\n",
        "    source = extract_source_webpage(search_data[\"link\"])\n",
        "\n",
        "  date = None\n",
        "\n",
        "  title = None\n",
        "  if \"question\" in search_data:\n",
        "    title = search_data[\"question\"]\n",
        "\n",
        "  snippet = None\n",
        "  if \"answer\" in search_data:\n",
        "    snippet = search_data[\"answer\"]\n",
        "\n",
        "  highlight = None\n",
        "\n",
        "  return {\n",
        "      \"source\": source,\n",
        "      \"date\": date,\n",
        "      \"title\": title,\n",
        "      \"snippet\": snippet,\n",
        "      \"highlight\": highlight,\n",
        "  }\n",
        "\n",
        "# 对freshprompt进行格式化\n",
        "def freshprompt_format(\n",
        "    question,\n",
        "    search_data,\n",
        "    reasoning_and_answer,\n",
        "    num_organic_results,\n",
        "    num_related_questions,\n",
        "    num_questions_and_answers,\n",
        "    num_retrieved_evidences,\n",
        "):\n",
        "  \"\"\"Build FreshPrompt for each question\n",
        "\n",
        "  Args:\n",
        "    question: The question to process.\n",
        "    search_data: Search data.\n",
        "    reasoning_and_answer: The reasoning and answer.\n",
        "    num_organic_results: Number of organic results to keep.\n",
        "    num_related_questions: Number of related questions to keep.\n",
        "    num_questions_and_answers: Number of questions and answers to keep.\n",
        "    num_retrieved_evidences: Number of retrieved evidences to keep.\n",
        "\n",
        "  Returns:\n",
        "    A prompt that incorporates retrieved evidences for each question.\n",
        "  \"\"\"\n",
        "\n",
        "  df = pd.DataFrame(columns=['source', 'date', 'title', 'snippet', 'highlight'])\n",
        "\n",
        "  # Organic results\n",
        "  organic_results = [None] * num_organic_results\n",
        "  for k in range(num_organic_results):\n",
        "    if (\n",
        "        'organic_results' in search_data\n",
        "        and len(search_data['organic_results']) > k\n",
        "    ):\n",
        "      organic_results[k] = format_search_results(\n",
        "          search_data['organic_results'][k]\n",
        "      )\n",
        "    else:\n",
        "      organic_results[k] = format_search_results({})\n",
        "\n",
        "  for d in organic_results[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Related questions\n",
        "  related_questions = [None] * num_related_questions\n",
        "  for k in range(num_related_questions):\n",
        "    if (\n",
        "        'related_questions' in search_data\n",
        "        and len(search_data['related_questions']) > k\n",
        "    ):\n",
        "      related_questions[k] = format_search_results(\n",
        "          search_data['related_questions'][k], title_field='question'\n",
        "      )\n",
        "    else:\n",
        "      related_questions[k] = format_search_results({})\n",
        "\n",
        "  for d in related_questions[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Questions and Answers\n",
        "  questions_and_answers = [None] * num_questions_and_answers\n",
        "  for k in range(num_questions_and_answers):\n",
        "    if (\n",
        "        'questions_and_answers' in search_data\n",
        "        and len(search_data['questions_and_answers']) > k\n",
        "    ):\n",
        "      questions_and_answers[k] = format_questions_and_answers(\n",
        "          search_data['questions_and_answers'][k]\n",
        "      )\n",
        "    else:\n",
        "      questions_and_answers[k] = format_questions_and_answers({})\n",
        "\n",
        "  for d in questions_and_answers[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Knowledge graph\n",
        "  knowledge_graph = None\n",
        "  if 'knowledge_graph' in search_data:\n",
        "    knowledge_graph = format_knowledge_graph(search_data['knowledge_graph'])\n",
        "  else:\n",
        "    knowledge_graph = format_knowledge_graph({})\n",
        "  df = pd.concat([df, pd.DataFrame([knowledge_graph])], ignore_index=True)\n",
        "\n",
        "  # Answer box\n",
        "  answer_box = None\n",
        "  if 'answer_box' in search_data:\n",
        "    answer_box = format_search_results(\n",
        "        search_data['answer_box'], highlight_field='answer'\n",
        "    )\n",
        "  else:\n",
        "    answer_box = format_search_results({})\n",
        "  df = pd.concat([df, pd.DataFrame([answer_box])], ignore_index=True)\n",
        "\n",
        "  # Sort by date\n",
        "  df['date'] = df['date'].apply(lambda x: format_date(x))\n",
        "  df['datetime'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "  df = df.sort_values(by='datetime', na_position='first')\n",
        "  df.replace({pd.NaT: None}, inplace=True)\n",
        "  df = df.dropna(how='all')\n",
        "\n",
        "  # Select top_k supporting evidences overall\n",
        "  evidences = []\n",
        "\n",
        "  for _, row in df.tail(num_retrieved_evidences).iterrows():\n",
        "    evidences.append(\n",
        "        f\"\"\"\\n\\nsource: {row['source']}\\ndate: {row['date']}\\ntitle: {row['title']}\\nsnippet: {row['snippet']}\\nhighlight: {row['highlight']}\"\"\"\n",
        "    )\n",
        "\n",
        "  return (\n",
        "      ''.join(\n",
        "          [\n",
        "              f'\\n\\n\\nquery: {question}',\n",
        "          ]\n",
        "          + evidences\n",
        "      )\n",
        "      + f'\\n\\nquestion: {question}{reasoning_and_answer}'\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "xmQZYfPD3sxL"
      },
      "outputs": [],
      "source": [
        "#@title Demonstration examples\n",
        "\n",
        "\n",
        "demo_questions = [\n",
        "    \"What year is considered Albert Einstein's annus mirabilis?\",\n",
        "    \"Which photographer took the most expensive photograph in the world?\",\n",
        "    \"How many days are left until the 2023 Grammy Awards?\",\n",
        "    \"How many years ago did the Boxing Day Tsunami happen?\",\n",
        "    (\n",
        "        \"When did Amazon become the first publicly traded company to exceed a\"\n",
        "        \" market value of $3 trillion?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "concise_demo_reasonings_and_answers = [\n",
        "    (\n",
        "        \"1905 is considered Albert Einstein's annus mirabilis, his miraculous\"\n",
        "        \" year.\"\n",
        "    ),\n",
        "    (\n",
        "        'The most expensive photograph in the world is \"Le Violon d\\'Ingres\".'\n",
        "        \" The photograph was created by Man Ray.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The 2023 Grammy Awards ceremony was held on February 5, 2023. Thus,\"\n",
        "        \" the ceremony has already taken place.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The disaster occurred on December 26, 2004. Thus, it happened 19 years\"\n",
        "        \" ago.\"\n",
        "    ),\n",
        "    \"Amazon's market capitalization has never exceeded $3 trillion.\",\n",
        "]\n",
        "\n",
        "verbose_demo_reasonings_and_answers = [\n",
        "    (\n",
        "        \"In the year of 1905, Albert Einstein published four groundbreaking\"\n",
        "        \" papers that revolutionized scientific understanding of the universe.\"\n",
        "        \" Thus, scientists call 1905 Albert Einstein's annus mirabilis — his\"\n",
        "        \" year of miracles.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Man Ray's famed \\\"Le Violon d'Ingres\\\" became the most expensive\"\n",
        "        \" photograph ever to sell at auction, sold for $12.4 million on May\"\n",
        "        \" 14th, 2022 at Christie's New York. The black and white image, taken\"\n",
        "        \" in 1924 by the American surrealist artist, transforms a woman's naked\"\n",
        "        \" body into a violin by overlaying the picture of her back with\"\n",
        "        \" f-holes. Thus, Man Ray is the photographer who took the most\"\n",
        "        \" expensive photograph in the world.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The 2023 Grammy Awards, officially known as the 65th Annual Grammy\"\n",
        "        \" Awards ceremony, was held in Los Angeles on February 5, 2023. Thus,\"\n",
        "        \" the event has already taken place.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The Boxing Day Tsunami refers to the 2004 Indian Ocean earthquake and\"\n",
        "        \" tsunami, which is one of the deadliest natural disasters in recorded\"\n",
        "        \" history, killing an estimated 230,000 people across 14 countries. The\"\n",
        "        \" disaster occurred on December 26, 2004, which is 19 years ago.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Amazon's market capitalization hit a peak of roughly $1.9 trillion in\"\n",
        "        \" July 2021. In 2022, Amazon became the first public company ever to\"\n",
        "        \" lose $1 trillion in market value. Thus, Amazon's market value has\"\n",
        "        \" never exceeded $3 trillion. In fact, Apple became the first publicly\"\n",
        "        \" traded U.S. company to exceed a market value of $3 trillion in\"\n",
        "        \" January 2022.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "prefix = (\n",
        "    f\"\\nanswer: As of today {current_date}, the most up-to-date and relevant\"\n",
        "    \" information regarding this query is as follows. \"\n",
        ")\n",
        "\n",
        "concise_demo_reasonings_and_answers = [\n",
        "    prefix + x for x in concise_demo_reasonings_and_answers\n",
        "]\n",
        "verbose_demo_reasonings_and_answers = [\n",
        "    prefix + x for x in verbose_demo_reasonings_and_answers\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "MS6fKTK-A8bY"
      },
      "outputs": [],
      "source": [
        "#@title Retrieving search data for demonstration examples\n",
        "\n",
        "\n",
        "demo_search_data = [call_search_engine(q) for q in demo_questions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "fAcuImw5EP5T"
      },
      "outputs": [],
      "source": [
        "# 调用 freshprompt 函数\n",
        "\n",
        "def call_freshprompt(model, question, check_premise=False, verbose=False):\n",
        "  # 初始化模型参数\n",
        "  temperature = 0.0  # 模型的温度参数，影响生成结果的随机性\n",
        "  max_tokens = 256  # 最大生成的token数量\n",
        "  chat_completions = True  # 是否使用对话完成模式\n",
        "\n",
        "  # 根据模型类型设置不同的参数\n",
        "  if model.startswith('gpt-4'):\n",
        "    num_organic_results = 15  # 自然搜索结果数量\n",
        "    num_related_questions = 3  # 相关问题数量\n",
        "    num_questions_and_answers = 3  # 问答对数量\n",
        "    num_retrieved_evidences = 15  # 检索到的证据数量\n",
        "  else:\n",
        "    num_organic_results = 15\n",
        "    num_related_questions = 2\n",
        "    num_questions_and_answers = 2\n",
        "    num_retrieved_evidences = 5\n",
        "\n",
        "  # 选择推理和回答示例的格式\n",
        "  if verbose:\n",
        "    demo_reasonings_and_answers = verbose_demo_reasonings_and_answers\n",
        "  else:\n",
        "    demo_reasonings_and_answers = concise_demo_reasonings_and_answers\n",
        "\n",
        "  # 生成示例提示\n",
        "  demo_prompts = []\n",
        "  for q, s, ra in zip(\n",
        "      demo_questions, demo_search_data, concise_demo_reasonings_and_answers\n",
        "  ):\n",
        "      demo_prompts.append(\n",
        "      freshprompt_format(\n",
        "          q,  # 示例问题\n",
        "          s,  # 搜索数据\n",
        "          ra,  # 推理和回答\n",
        "          num_organic_results,\n",
        "          num_related_questions,\n",
        "          num_questions_and_answers,\n",
        "          num_retrieved_evidences,\n",
        "      )\n",
        "      )\n",
        "\n",
        "  freshprompt_demo = ''.join(demo_prompts).strip()  # 将所有示例提示拼接成一个字符串\n",
        "\n",
        "  # 根据是否检查前提来设置后缀\n",
        "  if check_premise:\n",
        "    suffix = (\n",
        "        \"\\nPlease check if the question contains a valid premise before\"\n",
        "        \" answering.\\nanswer: \"\n",
        "    )\n",
        "  else:\n",
        "    suffix = \"\\nanswer: \"\n",
        "\n",
        "  # 生成用户问题的提示\n",
        "  freshprompt_question = freshprompt_format(\n",
        "      question,  # 用户问题\n",
        "      call_search_engine(question),  # 调用搜索引擎获取相关数据\n",
        "      suffix,  # 后缀\n",
        "      num_organic_results,# 结果\n",
        "      num_related_questions,# 相关问题\n",
        "      num_questions_and_answers,# QA的数量\n",
        "      num_retrieved_evidences,# 检索增强证据\n",
        "  )\n",
        "\n",
        "  # 拼接示例提示和用户问题提示\n",
        "  fresh_prompt = freshprompt_demo + freshprompt_question # 将这两部分相加\n",
        "  # 前一部分是示例，后一部分是要问的问题。\n",
        "\n",
        "  # 调用大语言模型API获取答案\n",
        "  answer = call_llm_api(\n",
        "      fresh_prompt, model, temperature, max_tokens, chat_completions\n",
        "  )\n",
        "  return answer  # 返回生成的答案\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# question = \"现在的中国国家主席是胡锦涛。\"\n",
        "# check_premise=False\n",
        "# answer = call_llm_api(model_name,question, check_premise=check_premise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e341fa1398f1464bb4dddee86365410d",
            "cfbb04a5dce540949c96f46290ba2273",
            "86c6583dc7fc48ebbb94665fd04dcfbe",
            "b0ee2576f40a465f96141e5dfe28de39",
            "36edaa5501b04ddcbdaa7aa009a82fc3"
          ]
        },
        "id": "QB_Cm9mjG3OD",
        "outputId": "76125060-f939-4765-cdbe-ffd84610a2b4"
      },
      "outputs": [
        {
          "ename": "APIConnectionError",
          "evalue": "Connection error.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_sync\\http_proxy.py:289\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    283\u001b[0m connect_request \u001b[38;5;241m=\u001b[39m Request(\n\u001b[0;32m    284\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONNECT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    285\u001b[0m     url\u001b[38;5;241m=\u001b[39mconnect_url,\n\u001b[0;32m    286\u001b[0m     headers\u001b[38;5;241m=\u001b[39mconnect_headers,\n\u001b[0;32m    287\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    288\u001b[0m )\n\u001b[1;32m--> 289\u001b[0m connect_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnect_request\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect_response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m connect_response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m299\u001b[39m:\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection.py:99\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection.py:76\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_sync\\connection.py:122\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 122\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_backends\\sync.py:205\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    200\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    201\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    203\u001b[0m }\n\u001b[1;32m--> 205\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[1;31mConnectError\u001b[0m: [WinError 10061] 由于目标计算机积极拒绝，无法连接。",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:952\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 952\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_transports\\default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[1;32m--> 232\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[1;31mConnectError\u001b[0m: [WinError 10061] 由于目标计算机积极拒绝，无法连接。",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# @markdown ### Ask your question here!\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# question = \"Who is the latest artist confirmed to be performing during the 2024 Grammys telecast?\"  # @param {type:\"string\"}\u001b[39;00m\n\u001b[0;32m      9\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m中国国家主席现在是谁\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mcall_freshprompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_premise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_premise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Directly output the answer\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
            "Cell \u001b[1;32mIn[13], line 70\u001b[0m, in \u001b[0;36mcall_freshprompt\u001b[1;34m(model, question, check_premise, verbose)\u001b[0m\n\u001b[0;32m     67\u001b[0m fresh_prompt \u001b[38;5;241m=\u001b[39m freshprompt_demo \u001b[38;5;241m+\u001b[39m freshprompt_question\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 调用大语言模型API获取答案\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfresh_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_completions\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
            "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mcall_llm_api\u001b[1;34m(prompt, model, temperature, max_tokens, chat_completions)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_llm_api\u001b[39m(prompt, model, temperature, max_tokens, chat_completions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;66;03m# 参见https://platform.openai.com/docs/guides/gpt获取详细信息\u001b[39;00m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m chat_completions:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# 调用聊天模式的API\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 使用指定的模型\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 设置生成文本的随机性\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 设置生成文本的最大长度\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 系统角色消息，用于设置助手的行为\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant. Answer as concisely as\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m possible. Knowledge cutoff: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_date\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 提供上下文和知识截断日期\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms today\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms date?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 用户消息示例\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mToday is \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_date\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m in Pacific Standard Time.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 助手响应示例\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 实际用户提示消息\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent  \u001b[38;5;66;03m# 返回生成的文本内容\u001b[39;00m\n\u001b[0;32m     28\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# 调用完成模式的API\u001b[39;00m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:976\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    973\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:976\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    973\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\D\\Python\\Lib\\site-packages\\openai\\_base_client.py:986\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    977\u001b[0m             options,\n\u001b[0;32m    978\u001b[0m             cast_to,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    982\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    983\u001b[0m         )\n\u001b[0;32m    985\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    990\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    994\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    995\u001b[0m )\n\u001b[0;32m    996\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "\u001b[1;31mAPIConnectionError\u001b[0m: Connection error."
          ]
        }
      ],
      "source": [
        "#@title FreshPrompt\n",
        "\n",
        "# @markdown ---\n",
        "model_name = \"gpt-3.5-turbo\" #@param [\"gpt-4-0125-preview\", \"gpt-4-turbo-preview\", \"gpt-4-1106-preview\", \"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-instruct\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-0301\"]\n",
        "check_premise = True  # @param {type:\"boolean\"}\n",
        "# @markdown ### Ask your question here!\n",
        "\n",
        "# question = \"Who is the latest artist confirmed to be performing during the 2024 Grammys telecast?\"  # @param {type:\"string\"}\n",
        "question = \"中国国家主席现在是谁\"\n",
        "answer = call_freshprompt(model_name, question, check_premise=check_premise)\n",
        "\n",
        "# Directly output the answer\n",
        "print(answer)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36edaa5501b04ddcbdaa7aa009a82fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c6583dc7fc48ebbb94665fd04dcfbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b0ee2576f40a465f96141e5dfe28de39": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_36edaa5501b04ddcbdaa7aa009a82fc3",
            "msg_id": "",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "\n",
                  "As of January 28, 2024, the latest artist confirmed to be performing during the 2024 Grammys telecast is Joni Mitchell.\n"
                ]
              }
            ]
          }
        },
        "cfbb04a5dce540949c96f46290ba2273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e341fa1398f1464bb4dddee86365410d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "SHOW ANSWER",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cfbb04a5dce540949c96f46290ba2273",
            "style": "IPY_MODEL_86c6583dc7fc48ebbb94665fd04dcfbe",
            "tooltip": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
